import type { AIAPIConfig, TaskGenerationRequest } from '../types';
import { AIServiceError } from '../types';

interface AIResponse {
  tasks: Array<{
    content: string;
    type: 'character' | 'word' | 'phrase';
    details: {
      strokes?: number;
      repetitions?: number;
      sentence?: string;
    };
    reward: number;
  }>;
}

export class AIService {
  static async generateTaskContent(
    config: AIAPIConfig,
    request: TaskGenerationRequest
  ): Promise<AIResponse> {
    const prompt = this.buildPrompt(request);
    
    try {
      switch (config.model) {
        case 'gemini':
          return await this.callGeminiAPI(config.apiKey, prompt);
        case 'openai':
          return await this.callOpenAIAPI(config.apiKey, prompt);
        case 'claude':
          return await this.callClaudeAPI(config.apiKey, prompt);
        default:
          throw new Error(`Unsupported AI model: ${config.model}`);
      }
    } catch (error) {
      console.error('AI Service Error:', error);
      if (error instanceof AIServiceError) {
        throw error;
      }
      throw new AIServiceError('Failed to generate tasks from AI service', 'UNKNOWN', error);
    }
  }

  private static buildPrompt(request: TaskGenerationRequest): string {
    const previousTasksList = (request.previousTasks && request.previousTasks.length > 0)
      ? request.previousTasks.join('ã€') 
      : 'ç„¡';
    
    return `
è«‹ç‚ºåœ‹å°${request.grade}å¹´ç´šå­¸ç”Ÿï¼ˆ${request.userAge}æ­²ï¼‰ç”Ÿæˆä»Šæ—¥çš„ä¸­æ–‡å­¸ç¿’ä»»å‹™ã€‚

**é‡è¦ç´„æŸæ¢ä»¶ï¼š**
ğŸš« **çµ•å°ä¸å¯ä½¿ç”¨ä»¥ä¸‹å·²å­¸éçš„å­—è©ï¼š** ${previousTasksList}

**ä»»å‹™ç”Ÿæˆè¦æ±‚ï¼ˆæå‡æŒ‘æˆ°æ€§ï¼‰ï¼š**
1. ç”Ÿæˆ3å€‹**é«˜å“è³ªä¸”å…·æŒ‘æˆ°æ€§**çš„ä»»å‹™
2. ä»»å‹™å¿…é ˆåŒ…å«ï¼š
   - 1å€‹å–®å­—ä»»å‹™ï¼ˆç­†åŠƒæ•¸8åŠƒä»¥ä¸Šçš„è¼ƒè¤‡é›œå­—ï¼‰
   - 1å€‹è©èªæ‡‰ç”¨ä»»å‹™ï¼ˆç†è§£è©æ„ä¸¦å®Œæˆé€ å¥ç·´ç¿’ï¼‰
   - 1å€‹è©èªæ›¸å¯«ä»»å‹™ï¼ˆé›™å­—è©ï¼Œéœ€é‡è¤‡ç·´ç¿’ï¼‰
3. æ¯å€‹ä»»å‹™åŒ…å«ï¼š
   - content: è¦å­¸ç¿’çš„å­—æˆ–è©ï¼ˆé¸æ“‡æœ‰æ•™è‚²åƒ¹å€¼ä¸”æœ‰ä¸€å®šé›£åº¦çš„å…§å®¹ï¼‰
   - type: "character"(å–®å­—) | "word"(å–®è©æ›¸å¯«) | "phrase"(è©èªé€ å¥æ‡‰ç”¨)
   - details: ç­†åŠƒæ•¸ã€ç·´ç¿’æ¬¡æ•¸ï¼ˆè‡³å°‘5æ¬¡ï¼‰ã€æˆ–é€ å¥è¦æ±‚ï¼ˆä¸æ¶‰åŠæ™‚é–“ï¼‰
   - reward: æ ¹æ“šæ–°çš„åš´æ ¼æ¨™æº–è¨ˆç®—

**çå‹µè¨ˆç®—è¦å‰‡ï¼ˆæ›´åš´æ ¼çš„æ¨™æº–ï¼‰ï¼š**
- å–®å­—ä»»å‹™ï¼š3 + é›£åº¦åŠ æˆ(8-12åŠƒ+1, 13-16åŠƒ+2, 17+åŠƒ+3) + æ¬¡æ•¸åŠ æˆ(5-7æ¬¡+1, 8-10æ¬¡+2)ï¼Œä¸Šé™8
- è©èªé€ å¥æ‡‰ç”¨ï¼šç†è§£è©æ„ä¸¦é€ å¥ï¼Œå›ºå®š5å­¸ç¿’å¹£
- è©èªæ›¸å¯«ï¼š4 + æ¬¡æ•¸åŠ æˆ(éœ€æ›¸å¯«6æ¬¡ä»¥ä¸Š)

**å¹´ç´š${request.grade}é©åˆçš„å­—è©ç¯„åœï¼ˆæå‡é›£åº¦ï¼‰ï¼š**
${request.grade <= 2 ? 'äºŒå¹´ç´šé€²éšå­—è©ï¼šåŒ…å«å½¢è²å­—ã€æœƒæ„å­—ã€å¸¸ç”¨è¤‡åˆè©ï¼Œå¦‚ã€Œè°æ˜ã€ã€ã€Œç¾éº—ã€ã€ã€Œæ•…äº‹ã€ã€ã€Œæœ‹å‹ã€ç­‰' : 
  request.grade <= 4 ? 'ä¸­é«˜å¹´ç´šå­—è©ï¼šåŒ…å«æˆèªã€å¤šéŸ³å­—ã€åŒç¾©è©ï¼Œå¦‚ã€ŒåŠªåŠ›ã€ã€ã€Œå‹‡æ•¢ã€ã€ã€ŒèªçœŸã€ç­‰' : 
  'é«˜å¹´ç´šå­—è©ï¼šåŒ…å«æˆèªã€å¤è©©è©ã€æ–‡å­¸ç”¨èªã€å°ˆæ¥­è©å½™'}

**é©—è­‰æ­¥é©Ÿï¼š**
1. æª¢æŸ¥ç”Ÿæˆçš„æ¯å€‹å­—/è©æ˜¯å¦å‡ºç¾åœ¨ç¦ç”¨åˆ—è¡¨ä¸­
2. å¦‚æœæœ‰é‡è¤‡ï¼Œè«‹ç«‹å³æ›¿æ›ç‚ºå…¶ä»–é©åˆçš„å­—è©
3. ç¢ºä¿æœ€çµ‚çµæœå®Œå…¨é¿é–‹å·²å­¸éçš„å…§å®¹

**åœ‹å°${request.grade}å¹´ç´šç¯„ä¾‹ï¼ˆæå‡é›£åº¦å¾Œï¼‰ï¼š**
- å–®å­—ç¯„ä¾‹ï¼šã€Œè°ã€(17åŠƒï¼Œç·´ç¿’7æ¬¡) â†’ çå‹µï¼š3+3+1=7å­¸ç¿’å¹£
- è©èªé€ å¥æ‡‰ç”¨ç¯„ä¾‹ï¼šã€ŒåŠªåŠ›ã€â†’ã€Œè«‹ç”¨ã€åŠªåŠ›ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œå±•ç¾åŠªåŠ›çš„æ„æ€ã€â†’ å›ºå®š5å­¸ç¿’å¹£  
- è©èªæ›¸å¯«ç¯„ä¾‹ï¼šã€Œç¾éº—ã€(ç·´ç¿’6æ¬¡) â†’ çå‹µï¼š4+1=5å­¸ç¿’å¹£

è«‹å›å‚³JSONæ ¼å¼ï¼š
{
  "tasks": [
    {
      "content": "è°",
      "type": "character", 
      "details": {"strokes": 17, "repetitions": 7},
      "reward": 7
    },
    {
      "content": "åŠªåŠ›",
      "type": "phrase",
      "details": {"sentence": "è«‹ç”¨ã€åŠªåŠ›ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œå±•ç¾åŠªåŠ›çš„æ„æ€"},
      "reward": 5
    },
    {
      "content": "ç¾éº—", 
      "type": "word",
      "details": {"repetitions": 6},
      "reward": 5
    }
  ]
}
`;
  }

  private static async callGeminiAPI(apiKey: string, prompt: string): Promise<AIResponse> {
    try {
      const response = await fetch(
        'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent',
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-goog-api-key': apiKey,
          },
          body: JSON.stringify({
            contents: [{ parts: [{ text: prompt }] }],
          }),
        }
      );

      if (!response.ok) {
        if (response.status === 401 || response.status === 403) {
          throw new AIServiceError(
            'API Key ç„¡æ•ˆæˆ–æ¬Šé™ä¸è¶³ï¼Œè«‹æª¢æŸ¥ä½ çš„ Gemini API Key',
            'AUTH_ERROR'
          );
        }
        if (response.status === 429) {
          throw new AIServiceError(
            'API è«‹æ±‚æ¬¡æ•¸éå¤šï¼Œè«‹ç¨å¾Œå†è©¦',
            'RATE_LIMIT'
          );
        }
        throw new AIServiceError(
          `Gemini API éŒ¯èª¤ï¼š${response.status} ${response.statusText}`,
          'NETWORK_ERROR'
        );
      }

      const data = await response.json();
      const text = data.candidates?.[0]?.content?.parts?.[0]?.text;
      
      if (!text) {
        throw new AIServiceError('Gemini API æ²’æœ‰å›å‚³å…§å®¹', 'INVALID_RESPONSE');
      }

      return this.parseAIResponse(text);
    } catch (error) {
      if (error instanceof AIServiceError) {
        throw error;
      }
      if (error instanceof TypeError && error.message.includes('fetch')) {
        throw new AIServiceError('ç¶²è·¯é€£ç·šå¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š', 'NETWORK_ERROR', error);
      }
      throw new AIServiceError('å‘¼å« Gemini API æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤', 'UNKNOWN', error);
    }
  }

  private static async callOpenAIAPI(apiKey: string, prompt: string): Promise<AIResponse> {
    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [{ role: 'user', content: prompt }],
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        if (response.status === 401) {
          throw new AIServiceError(
            'API Key ç„¡æ•ˆæˆ–æ¬Šé™ä¸è¶³ï¼Œè«‹æª¢æŸ¥ä½ çš„ OpenAI API Key',
            'AUTH_ERROR'
          );
        }
        if (response.status === 429) {
          throw new AIServiceError(
            'API è«‹æ±‚æ¬¡æ•¸éå¤šï¼Œè«‹ç¨å¾Œå†è©¦',
            'RATE_LIMIT'
          );
        }
        throw new AIServiceError(
          `OpenAI API éŒ¯èª¤ï¼š${response.status} ${response.statusText}`,
          'NETWORK_ERROR'
        );
      }

      const data = await response.json();
      const text = data.choices?.[0]?.message?.content;
      
      if (!text) {
        throw new AIServiceError('OpenAI API æ²’æœ‰å›å‚³å…§å®¹', 'INVALID_RESPONSE');
      }

      return this.parseAIResponse(text);
    } catch (error) {
      if (error instanceof AIServiceError) {
        throw error;
      }
      if (error instanceof TypeError && error.message.includes('fetch')) {
        throw new AIServiceError('ç¶²è·¯é€£ç·šå¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š', 'NETWORK_ERROR', error);
      }
      throw new AIServiceError('å‘¼å« OpenAI API æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤', 'UNKNOWN', error);
    }
  }

  private static async callClaudeAPI(apiKey: string, prompt: string): Promise<AIResponse> {
    try {
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': apiKey,
          'anthropic-version': '2023-06-01',
        },
        body: JSON.stringify({
          model: 'claude-3-5-sonnet-20241022',
          max_tokens: 1000,
          messages: [{ role: 'user', content: prompt }],
        }),
      });

      if (!response.ok) {
        if (response.status === 401) {
          throw new AIServiceError(
            'API Key ç„¡æ•ˆæˆ–æ¬Šé™ä¸è¶³ï¼Œè«‹æª¢æŸ¥ä½ çš„ Claude API Key',
            'AUTH_ERROR'
          );
        }
        if (response.status === 429) {
          throw new AIServiceError(
            'API è«‹æ±‚æ¬¡æ•¸éå¤šï¼Œè«‹ç¨å¾Œå†è©¦',
            'RATE_LIMIT'
          );
        }
        throw new AIServiceError(
          `Claude API éŒ¯èª¤ï¼š${response.status} ${response.statusText}`,
          'NETWORK_ERROR'
        );
      }

      const data = await response.json();
      const text = data.content?.[0]?.text;
      
      if (!text) {
        throw new AIServiceError('Claude API æ²’æœ‰å›å‚³å…§å®¹', 'INVALID_RESPONSE');
      }

      return this.parseAIResponse(text);
    } catch (error) {
      if (error instanceof AIServiceError) {
        throw error;
      }
      if (error instanceof TypeError && error.message.includes('fetch')) {
        throw new AIServiceError('ç¶²è·¯é€£ç·šå¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š', 'NETWORK_ERROR', error);
      }
      throw new AIServiceError('å‘¼å« Claude API æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤', 'UNKNOWN', error);
    }
  }

  private static parseAIResponse(text: string): AIResponse {
    try {
      // Extract JSON from the response text
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new AIServiceError('AI å›æ‡‰ä¸­æ²’æœ‰æ‰¾åˆ° JSON æ ¼å¼çš„å…§å®¹', 'INVALID_RESPONSE');
      }
      
      const parsed = JSON.parse(jsonMatch[0]);
      
      if (!parsed.tasks || !Array.isArray(parsed.tasks)) {
        throw new AIServiceError('AI å›æ‡‰æ ¼å¼ä¸æ­£ç¢ºï¼Œç¼ºå°‘ä»»å‹™é™£åˆ—', 'INVALID_RESPONSE');
      }
      
      return parsed;
    } catch (error) {
      console.error('Failed to parse AI response:', text);
      
      if (error instanceof AIServiceError) {
        throw error;
      }
      
      // Return fallback tasks if parsing fails
      console.warn('ä½¿ç”¨é è¨­ä»»å‹™ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ');
      return {
        tasks: [
          {
            content: 'å­¸',
            type: 'character',
            details: { strokes: 8, repetitions: 5 },
            reward: 7
          }
        ]
      };
    }
  }
}